services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - APP_NAME=${APP_NAME:-Wizard AI Agent}
      - ENV=${ENV:-prod}
      - MODEL_TYPE=${MODEL_TYPE:-hybrid}
      - MODEL_NAME=${MODEL_NAME:-deepseek-r1}
      - MODEL_PATH=${MODEL_PATH:-./fine_tuned_model}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
    volumes:
      - ./backend/fine_tuned_model:/app/fine_tuned_model
      - ./backend:/app/backend:ro # Mount source code as read-only for production safety
    restart: always

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000 # Browser access
    depends_on:
      - backend
    restart: always
